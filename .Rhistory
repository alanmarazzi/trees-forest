views <- seq(1000, 50e6, 250000)
video <- seq(1, 200, 5)
format <- seq(1, 100, 5)
margins <- expand.grid(views = views, video = video, format = format)
margins$cpv <- (margins$video + margins$format * 2) / margins$views + 0.05
margins$budget <- margins$cpv * margins$views
margins$margine <- margins$budget - (margins$views * .03 + margins$video * 1000 + margins$format * 1000)
margins$share <- margins$margine/margins$budget
margins_pos <- margins %>% filter(format <= video)
?scatterplot3d
install.packages("plot3D")
library(plot3D)
surf3D(margins_pos$views, margins_pos$video, margins_pos$format)
?surf3D
surf3D(as.matrix(margins_pos$views), as.matrix(margins_pos$video), as.matrix(margins_pos$format))
?surf3D
surf3D(as.matrix(margins_pos$views), as.matrix(margins_pos$video), as.matrix(margins_pos$format), as.matrix(margins$share))
scatter3D(as.matrix(margins_pos$views), as.matrix(margins_pos$video), as.matrix(margins_pos$format), as.matrix(margins$share))
?scatter3D
scatterplot3d(margins_pos$views, margins_pos$video, margins_pos$format)
margins <- margins %>% filter(format <= video)
margins_pos <- margins %>% filter(share >= 0.5)
View(margins)
margins_pos <- margins %>% filter(share >= 0.2)
View(margins_pos)
margins_pos <- margins %>% filter(share >= 0.3)
margins_pos <- margins %>% filter(share >= 0.4)
max(margins$share)
which.max(margins$share)
margins[200,]
which.min(margins$share)
margins[7801,]
margins$cpv <- (margins$video + margins$format * 2) / margins$views + 0.11
margins$budget <- margins$cpv * margins$views
margins$margine <- margins$budget - (margins$views * .03 + margins$video * 1000 + margins$format * 1000)
margins$share <- margins$margine/margins$budget
margins <- margins %>% filter(format <= video)
margins_pos <- margins %>% filter(share >= 0.5)
margins_pos <- margins %>% filter(share <= 0.2)
margins_pos <- margins %>% filter(share <= 0.1)
margins <- margins %>% filter(format <= video)
margins_pos <- margins %>% filter(share <= 0.1)
margins_pos <- margins %>% filter(share <= 0.05)
margins_pos <- margins %>% filter(share >= 0.75)
margins_pos <- margins %>% filter(share >= 0.65)
margins_pos <- margins %>% filter(share >= 0.7)
which.min(margins_pos$share)
margins[3007,]
margins$cpv <- (margins$video + margins$format * 2) / margins$views + 0.05
margins$budget <- margins$cpv * margins$views
margins$margine <- margins$budget - (margins$views * .03 + margins$video * 1000 + margins$format * 1000)
margins$share <- margins$margine/margins$budget
margins <- margins %>% filter(format <= video)
margins_pos <- margins %>% filter(share >= 0.7)
margins <- margins %>% filter(format <= video)
which.min(margins_pos$share)
margins$cpv <- (margins$video + margins$format * 2) / margins$views + 0.05
margins$budget <- margins$cpv * margins$views
margins$margine <- margins$budget - (margins$views * .03 + margins$video * 1000 + margins$format * 1000)
margins$share <- margins$margine/margins$budget
margins <- margins %>% filter(format <= video)
whic.min(margins$share)
which.min(margins$share)
margins[7801,]
0*2
margins$cpv <- (margins$video + margins$format * 2) / margins$views * 5000 + 0.05
margins$budget <- margins$cpv * margins$views
margins$margine <- margins$budget - (margins$views * .03 + margins$video * 1000 + margins$format * 1000)
margins$share <- margins$margine/margins$budget
margins <- margins %>% filter(format <= video)
which.min(margins$share)
margins[200,]
max(margins$share)
margins[which.max(margins$share),]
ggplot(margins, aes(video, margine))+
geom_line()
ggplot(margins, aes(video, margine, color = cpv))+
geom_line()
ggplot(margins, aes(video, margine, color = cpv))+
geom_line(size = 1)
ggplot(margins[margins$cpv < 500,], aes(video, margine, color = cpv))+
geom_line(size = 1)
ggplot(margins[margins$cpv < 100,], aes(video, margine, color = cpv))+
geom_line(size = 1)
ggplot(margins[margins$cpv < 25,], aes(video, margine, color = cpv))+
geom_line(size = 1)
ggplot(margins[margins$cpv < 5,], aes(video, margine, color = cpv))+
geom_line(size = 1)
ggplot(margins[margins$cpv < 1,], aes(video, margine, color = cpv))+
geom_line(size = 1)
ggplot(margins[margins$cpv < 1,], aes(video, margine, color = cpv))+
geom_point(size = 1)
views <- seq(1000, 20e6, 250000)
video <- seq(1, 200, 5)
format <- seq(1, 100, 5)
margins <- expand.grid(views = views, video = video, format = format)
margins$cpv <- (margins$video + margins$format * 2) / margins$views * 5000 + 0.05
margins$budget <- margins$cpv * margins$views
margins$margine <- margins$budget - (margins$views * .03 + margins$video * 1000 + margins$format * 1000)
margins$share <- margins$margine/margins$budget
margins <- margins %>% filter(format <= video)
ggplot(margins[margins$cpv < 1,], aes(video, margine, color = cpv))+
geom_point(size = 1)
ggplot(margins[margins$cpv < 1,], aes(views, margine, color = cpv))+
geom_point(size = 1)
View(margins)
views <- seq(10000, 20e6, 250000)
video <- seq(1, 200, 5)
format <- seq(1, 100, 5)
margins <- expand.grid(views = views, video = video, format = format)
margins$cpv <- (margins$video + margins$format * 2) / margins$views * 5000 + 0.05
margins$budget <- margins$cpv * margins$views
margins$margine <- margins$budget - (margins$views * .03 + margins$video * 1000 + margins$format * 1000)
margins$share <- margins$margine/margins$budget
margins <- margins %>% filter(format <= video)
ggplot(margins, aes(views, margine, color = cpv))+
geom_point(size = 1)
margins_pos <- margins %>% filter(share >= 0.4)
margins_pos <- margins %>% filter(share >= 0.6)
View(margins)
ggplot(margins, aes(views, margine, color = cpv))+
geom_point(size = 1)
?optim
fb <- seq(10000, 1e6, 10000)
ig <- seq(10000, 1e6, 10000)
pv <- seq(10000, 1e6, 10000)
td <- seq(10000, 1e6, 10000)
ld <- seq(10000, 1e6, 10000)
yt <- seq(10000, 1e6, 10000)
ot <- seq(10000, 1e6, 10000)
all <- expand.grid(fb, ig, pv, td, ld, yt, ot)
vec <- vec[(fb + ig + pv + td + ld + yt +ot) == 600000]
vec <- NULL
vec <- vec[(fb + ig + pv + td + ld + yt +ot) == 600000]
vec <- (fb + ig + pv + td + ld + yt + ot) == 600000
cpv <- 10/(fb*1.2+ig*1.1+pv*0.7+td*0.7+ld*0.5+yt*0.8+ot*0.6)*5000+.04
fb <- seq(10000, 1e5, 10000)
ig <- seq(10000, 1e5, 10000)
pv <- seq(10000, 1e5, 10000)
td <- seq(10000, 1e5, 10000)
ld <- seq(10000, 1e5, 10000)
yt <- seq(10000, 1e5, 10000)
ot <- seq(10000, 1e5, 10000)
all <- expand.grid(fb, ig, pv, td, ld, yt, ot)
class(all)
?rowsum
fb <- seq(10000, 1e5, 10000)
ig <- seq(10000, 1e5, 10000)
pv <- seq(10000, 1e5, 10000)
td <- seq(10000, 1e5, 10000)
ld <- seq(10000, 1e5, 10000)
yt <- seq(10000, 1e5, 10000)
ot <- seq(10000, 1e5, 10000)
all <- expand.grid(fb, ig, pv, td, ld, yt, ot)
all <- all[rowsum(all)==600000,]
?rowsum
all <- as.matrix(expand.grid(fb, ig, pv, td, ld, yt, ot))
all <- all[rowsum(all)==600000,]
?colSums
all <- all[rowSums(all)==600000,]
all <- as.data.frame(all[rowSums(all)==600000,])
all <- expand.grid(fb, ig, pv, td, ld, yt, ot)
all <- all[rowSums(all)==600000,]
all <- expand.grid(fb = fb, ig = ig, pv = pv, td = td, ld = ld, yt = yt, ot = ot)
all <- all[rowSums(all)==600000,]
all$format <- 2
all$video <- 6
?optim
all <- all[,-c(8,9)]
cpv <- function(x, y, z, w, a, b, p) {
10/(all$fb*x+all$ig*y,all$pv*z,all$td*w,all$ld*a,all$yt*b+all$ot*p)*5000+0,04
}
cpv <- function(x, y, z, w, a, b, p) {
10/(all$fb*x+all$ig*y+all$pv*z+all$td*w+all$ld*a+all$yt*b+all$ot*p)*5000+0.04
}
res <- optim(c(1,1,1,1,1,1,1), cpv)
all$format <- 2
all$video <- 6
all$cpv <- 10/(all$fb*1.2+all$ig*1.1+all$pv*0.7+all$td*0.7+all$ld*0.4+all$yt*0.8+all$ot*0.6)*5000+0.04
all$margine <- all$cpv*rowSums(all[,1:7])-(all$fb*0.02+all$ig*0.03+all$pv*0.12+all$td*0.12+all$ld*0.2+all$yt*0.05+all$ot*0.07)
all$share <- all$margine/(all$cpv*rowSums(all[,1:7]))
View(all)
mean(all$share)
min(all$share)
max(all$share)
library(dbConnect)
db_name <- "opportunities_dw"
con <- dbConnect(
MySQL(),
username = "bi-usr",
password = "fmqnk,c7277236.HJxi6o",
host = "pentaho.c7ebag6yytbj.eu-west-1.rds.amazonaws.com",
port = 3306,
dbname = db_name
)
activity <- dbGetQuery(con, "select * from activity")
opportunity <- dbGetQuery(con, "select * from opportunity")
phase <- dbGetQuery(con, "select * from phase")
funnel <- dbGetQuery(con, "select * from funnel")
area <- dbGetQuery(con, "select id,full_name,area_id,area from sales_manager")
View(activity)
as.Date(activity$created_at)
?as.Date
strptime(activity$created_at)
as.POSIXct(activity$created_at)
as.POSIXct()
?as.POSIXct
as.POSIXct(activity$created_at, tz = "Europe/Rome")
as.POSIXct(activity$created_at, tz = "UTC")
activity$created_at <- as.POSIXct(activity$created_at, tz = "UTC")
knitr::opts_chunk$set(fig.align = "center",echo = TRUE)
examData <- read.delim("~/Downloads/Exam Anxiety.dat")
cor(examData[,c("Exam", "Anxiety", "Revise")])
library(Hmisc)
examMatrix <- as.matrix(examData[,c("Exam", "Anxiety", "Revise")])
rcorr(examMatrix)
cor.test(examData$Anxiety, examData$Exam)
cor.test(examData$Anxiety, examData$Revise)
cor(examData[,c("Exam", "Anxiety", "Revise")])^2
liar <- read.delim("~/Downloads/The Biggest Liar.dat")
cor(liar$Position, liar$Creativity, method = "spearman")
liarMat <- as.matrix(liar[,c("Position", "Creativity")])
rcorr(liarMat)
cor(liar$Position, liar$Creativity, method = "kendall")
cor.test(liar$Position, liar$Creativity, alternative = "less", method = "kendall")
bootTau <- function(liar, i) {
cor(
liar$Position[i],
liar$Creativity[i],
use = "complete.obs",
method = "kendall"
)
}
library(boot)
boot_kendall <- boot(liar, bootTau, 2000)
boot_kendall
boot.ci(boot_kendall)
cats <- read.csv("~/Downloads/pbcorr.csv")
cor.test(cats$time, cats$gender)
examData2 <- examData[,c("Exam", "Anxiety", "Revise")]
library(ggm)
pc <- pcor(c("Exam", "Anxiety", "Revise"), var(examData2))
pc
pc^2
pcor.test(pc, q = 1, n = nrow(examData2))
zdiff <- function(r1, r2, n1, n2) {
zd <- (atanh(r1) - atanh(r2)) / sqrt(1 / (n1 - 3) + 1 / (n2 - 3))
p <- 1 - pnorm(abs(zd))
print(paste("Z Difference: ", zd))
print(paste("One-Tailed p-value: ", p))
}
zdiff(-.506, -.381, 52, 51)
tdiff <- function(rxy, rxz, rzy, n) {
df <- n - 3
td <- (rxy-rzy)*sqrt((df*(1+rxz))/(2*(1-rxy^2-rxz^2-rzy^2+(2*rxy*rxz*rzy))))
p <- pt(td, df)
print(paste("t Difference: ", td))
print(paste("One-Tailed p-value: ", p))
}
tdiff(-.441, -.709, .397, 103)
adder_maker <- function(x) {
function(n) {
x+n
}
}
add2 <- adder_maker(5)
add2(3)
library(purrr)
map_chr(c(5, 4, 3, 2, 1), function(x) {
c("one", "two", "three", "four", "five")[x]
})
map_if(1:5, function(x){
x %% 2 == 0
}, function(y) {
y^2
}) %>% unlist()
map_at(seq(100,500,100), c(1, 3, 5), function(x) {
x - 10
}) %>% unlist
map2_chr(letters, 1:26, paste)
pmap_chr(list(list(1, 2, 3),
list("one", "two", "three"),
list("uno", "due", "tre")), paste)
?message
reduce(c(1,3,5,7), function(x, y) {
message("x is ", x)
message("y is ", y)
message("")
x + y
})
reduce_right(letters[1:4], function(x, y) {
message("x is ", x)
message("y is ", y)
message("")
paste0(x, y)
})
contains(letters, "a")
detect(20:40, function(x) {
x > 22 && x %%2 == 0
})
keep(1:20, function(x) {
x %% 2 == 0
})
discard(1:20, function(x) {
x %% 2 == 0
})
every(1:20, function(x) {
x %% 2 == 0
})
n_unique <- compose(length, unique)
n_unique(rep(1:5, 1:5))
mult_three_n <- function(x, y, z) {
x * y * z
}
mult_by_15 <- partial(mult_three_n, x = 3, y = 5)
mult_by_15(z = 4)
walk(c("Friends, Romans, countrymen,",
"lend me your ears;",
"I come to bury Caesar,",
"not to praise him."), message)
vector_sum <- function(v) {
if (length(v) == 1) {
v
}else {
v[1] + vector_sum(v[-1])
}
}
vector_sum(c(5, 40, 91))
sum(c(5, 40, 91))
fib <- function(n) {
stopifnot(n > 0)
if (n == 1) {
0
} else if (n == 2) {
1
} else {
fib(n - 1) + fib(n - 2)
}
}
fib(1)
fib(5)
fib(20)
map_dbl(1:20, fib)
fib_tbl <- c(0, 1, rep(NA, 23))
fib_mem <- function(n) {
stopifnot(n > 0)
if (!is.na(fib_tbl[n])) {
fib_tbl[n]
} else {
fib_tbl[n-1] <<- fib_mem(n-1)
fib_tbl[n-2] <<- fib_mem(n-2)
fib_tbl[n - 1] + fib_tbl[n-2]
}
}
map_dbl(1:12, fib_mem)
map_dbl(1:12, fib_mem)
map_dbl(1:20, fib_mem)
map_dbl(1:30, fib_mem)
map_dbl(1:40, fib_mem)
fib_mem <- function(n) {
fib_tbl <- c(0, 1, rep(NA, 23))
stopifnot(n > 0)
if (!is.na(fib_tbl[n])) {
fib_tbl[n]
} else {
fib_tbl[n-1] <<- fib_mem(n-1)
fib_tbl[n-2] <<- fib_mem(n-2)
fib_tbl[n - 1] + fib_tbl[n-2]
}
}
map_dbl(1:40, fib_mem)
fib_mem <- function(n) {
fib_tbl <- c(0, 1, rep(NA, 23))
stopifnot(n > 0)
if (!is.na(fib_tbl[n])) {
fib_tbl[n]
} else {
fib_tbl[n-1] <<- fib_mem(n-1)
fib_tbl[n-2] <<- fib_mem(n-2)
fib_tbl[n - 1] + fib_tbl[n-2]
}
}
map_dbl(1:20, fib_mem)
fib_tbl <- c(0, 1, rep(NA, 23))
fib_mem <- function(n) {
stopifnot(n > 0)
if (!is.na(fib_tbl[n])) {
fib_tbl[n]
} else {
fib_tbl[n-1] <<- fib_mem(n-1)
fib_tbl[n-2] <<- fib_mem(n-2)
fib_tbl[n - 1] + fib_tbl[n-2]
}
}
map_dbl(1:20, fib_mem)
two_plus_two <- quote(2+2)
two_plus_two
eval(two_plus_two)
return_expression <- function(...) {
match.call()
}
return_expression(2, col = "blue", FALSE)
first_arg <- function(...) {
expr <- match.call()
first_arg_expr <- expr[[2]]
first_arg <- eval(first_arg_expr)
if (is.numeric(first_arg)) {
paste("The first argument is", first_arg)
} else {
"The first argument is not numeric"
}
}
first_arg(2, 4, "seven", FALSE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/Documents/personal/trees-forest/titanic.R', echo=TRUE)
titanic <- read.csv(
"https://raw.githubusercontent.com/alanmarazzi/trees-forest/master/data/train.csv",
stringsAsFactors = FALSE,
na.strings = "")
# Take a look at the structure of the dataset
str(titanic)
# The first thing I like to do is to convert all columns names to lowercase
names(titanic) <- tolower(names(titanic))
# sex and embarked to factors
titanic$sex <- as.factor(titanic$sex)
# Now convert to factor
titanic$embarked <- as.factor(titanic$embarked)
# The age variable has some missing values
mean(is.na(titanic$age))
# Deal with NA in age variable
age_prediction <- lm(age ~ survived + pclass + fare, data = titanic)
summary(age_prediction)
titanic$age[is.na(titanic$age)] <- predict(age_prediction,
newdata = titanic[is.na(titanic$age),])
# Check NAs in age
sum(is.na(titanic$age))
# Remove variables that clearly have nothing to do with our prediction setting
# and run a logistic regression as a benchmark
library(dplyr)
library(intubate)
logi <- titanic %>%
select(survived, pclass, sex, age, sibsp) %>%
ntbt_glm(survived ~ ., family = binomial)
summary(logi)
# Predict on training and test set
logi_pred <- predict(logi, type = "response")
survivors_logi <- rep(0, nrow(titanic))
survivors_logi[logi_pred > .5] <- 1
# This is going to be our benchmark
table(model = survivors_logi, real = titanic$survived)
(480 + 250)/nrow(titanic)
# Now on the test set for submission on Kaggle
test <- read.csv("https://raw.githubusercontent.com/alanmarazzi/trees-forest/master/data/test.csv",
stringsAsFactors = FALSE,
na.strings = "")
names(test) <- tolower(names(test))
test$sex <- as.factor(test$sex)
test_logi_pred <- predict(logi, test, type = "response")
surv_test_logi <- data.frame(PassengerId = test$passengerid,
Survived = rep(0, nrow(test)))
surv_test_logi$Survived[test_logi_pred > .5] <- 1
table(surv_test_logi$Survived)
write.csv(surv_test_logi, "results/logi.csv", row.names = FALSE)
setwd("~/documents/personal/trees-forest")
titanic <- read.csv(
"https://raw.githubusercontent.com/alanmarazzi/trees-forest/master/data/train.csv",
stringsAsFactors = FALSE,
na.strings = "")
# Take a look at the structure of the dataset
str(titanic)
# The first thing I like to do is to convert all columns names to lowercase
names(titanic) <- tolower(names(titanic))
# sex and embarked to factors
titanic$sex <- as.factor(titanic$sex)
# Now convert to factor
titanic$embarked <- as.factor(titanic$embarked)
# The age variable has some missing values
mean(is.na(titanic$age))
# Deal with NA in age variable
age_prediction <- lm(age ~ survived + pclass + fare, data = titanic)
summary(age_prediction)
titanic$age[is.na(titanic$age)] <- predict(age_prediction,
newdata = titanic[is.na(titanic$age),])
# Check NAs in age
sum(is.na(titanic$age))
# Remove variables that clearly have nothing to do with our prediction setting
# and run a logistic regression as a benchmark
library(dplyr)
library(intubate)
logi <- titanic %>%
select(survived, pclass, sex, age, sibsp) %>%
ntbt_glm(survived ~ ., family = binomial)
summary(logi)
# Predict on training and test set
logi_pred <- predict(logi, type = "response")
survivors_logi <- rep(0, nrow(titanic))
survivors_logi[logi_pred > .5] <- 1
# This is going to be our benchmark
table(model = survivors_logi, real = titanic$survived)
(480 + 250)/nrow(titanic)
# Now on the test set for submission on Kaggle
test <- read.csv("https://raw.githubusercontent.com/alanmarazzi/trees-forest/master/data/test.csv",
stringsAsFactors = FALSE,
na.strings = "")
names(test) <- tolower(names(test))
test$sex <- as.factor(test$sex)
test_logi_pred <- predict(logi, test, type = "response")
surv_test_logi <- data.frame(PassengerId = test$passengerid,
Survived = rep(0, nrow(test)))
surv_test_logi$Survived[test_logi_pred > .5] <- 1
table(surv_test_logi$Survived)
write.csv(surv_test_logi, "results/logi.csv", row.names = FALSE)
